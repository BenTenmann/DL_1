{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((60000, 28*28))\n",
    "x_train = x_train / 255\n",
    "x_test = x_test.reshape((10000, 28*28))\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.8204 - val_loss: 0.3544 - val_accuracy: 0.9118\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 0s 735us/step - loss: 0.3805 - accuracy: 0.8983 - val_loss: 0.2872 - val_accuracy: 0.9245\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 0s 733us/step - loss: 0.3329 - accuracy: 0.9085 - val_loss: 0.2621 - val_accuracy: 0.9308\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 0s 789us/step - loss: 0.3111 - accuracy: 0.9139 - val_loss: 0.2493 - val_accuracy: 0.9320\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 0s 788us/step - loss: 0.2979 - accuracy: 0.9165 - val_loss: 0.2413 - val_accuracy: 0.9347\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 0s 744us/step - loss: 0.2891 - accuracy: 0.9192 - val_loss: 0.2372 - val_accuracy: 0.9365\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 0s 776us/step - loss: 0.2825 - accuracy: 0.9208 - val_loss: 0.2359 - val_accuracy: 0.9372\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 0s 732us/step - loss: 0.2776 - accuracy: 0.9222 - val_loss: 0.2309 - val_accuracy: 0.9388\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 0s 718us/step - loss: 0.2730 - accuracy: 0.9238 - val_loss: 0.2295 - val_accuracy: 0.9387\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 0s 719us/step - loss: 0.2699 - accuracy: 0.9244 - val_loss: 0.2283 - val_accuracy: 0.9388\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 0s 718us/step - loss: 0.2667 - accuracy: 0.9250 - val_loss: 0.2262 - val_accuracy: 0.9385\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 0s 729us/step - loss: 0.2642 - accuracy: 0.9264 - val_loss: 0.2248 - val_accuracy: 0.9413\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 0s 816us/step - loss: 0.2620 - accuracy: 0.9266 - val_loss: 0.2238 - val_accuracy: 0.9417\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 0s 714us/step - loss: 0.2602 - accuracy: 0.9274 - val_loss: 0.2234 - val_accuracy: 0.9398\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 0s 707us/step - loss: 0.2581 - accuracy: 0.9287 - val_loss: 0.2240 - val_accuracy: 0.9390\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 0s 728us/step - loss: 0.2564 - accuracy: 0.9293 - val_loss: 0.2223 - val_accuracy: 0.9402\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 0s 719us/step - loss: 0.2554 - accuracy: 0.9288 - val_loss: 0.2218 - val_accuracy: 0.9408\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 0s 711us/step - loss: 0.2541 - accuracy: 0.9291 - val_loss: 0.2220 - val_accuracy: 0.9392\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 0s 722us/step - loss: 0.2525 - accuracy: 0.9300 - val_loss: 0.2217 - val_accuracy: 0.9413\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 0s 814us/step - loss: 0.2520 - accuracy: 0.9303 - val_loss: 0.2210 - val_accuracy: 0.9423\n"
     ]
    }
   ],
   "source": [
    "modelAdam = Sequential([\n",
    "    Dense(units=10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "\n",
    "modelAdam.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "history = modelAdam.fit(x_train, y_train, validation_split = 0.1, batch_size=batch_size, epochs=n_epoch)\n",
    "\n",
    "T = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 0s 866us/step - loss: 1.9836 - accuracy: 0.3983 - val_loss: 1.6645 - val_accuracy: 0.6477\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 0s 698us/step - loss: 1.5381 - accuracy: 0.6785 - val_loss: 1.3603 - val_accuracy: 0.7537\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 0s 752us/step - loss: 1.3172 - accuracy: 0.7394 - val_loss: 1.1810 - val_accuracy: 0.7970\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 0s 696us/step - loss: 1.1777 - accuracy: 0.7684 - val_loss: 1.0604 - val_accuracy: 0.8210\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 0s 710us/step - loss: 1.0800 - accuracy: 0.7868 - val_loss: 0.9728 - val_accuracy: 0.8368\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 0s 714us/step - loss: 1.0071 - accuracy: 0.7981 - val_loss: 0.9058 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 0s 728us/step - loss: 0.9502 - accuracy: 0.8068 - val_loss: 0.8527 - val_accuracy: 0.8557\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 0s 662us/step - loss: 0.9042 - accuracy: 0.8137 - val_loss: 0.8093 - val_accuracy: 0.8605\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 0s 690us/step - loss: 0.8661 - accuracy: 0.8201 - val_loss: 0.7731 - val_accuracy: 0.8655\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 0s 913us/step - loss: 0.8340 - accuracy: 0.8242 - val_loss: 0.7422 - val_accuracy: 0.8678\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 0s 965us/step - loss: 0.8063 - accuracy: 0.8286 - val_loss: 0.7156 - val_accuracy: 0.8702\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 0s 797us/step - loss: 0.7822 - accuracy: 0.8322 - val_loss: 0.6924 - val_accuracy: 0.8733\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 0s 666us/step - loss: 0.7610 - accuracy: 0.8359 - val_loss: 0.6719 - val_accuracy: 0.8748\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 0s 657us/step - loss: 0.7422 - accuracy: 0.8381 - val_loss: 0.6536 - val_accuracy: 0.8772\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 0s 656us/step - loss: 0.7253 - accuracy: 0.8407 - val_loss: 0.6373 - val_accuracy: 0.8792\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 0s 660us/step - loss: 0.7100 - accuracy: 0.8426 - val_loss: 0.6225 - val_accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 0s 659us/step - loss: 0.6962 - accuracy: 0.8446 - val_loss: 0.6090 - val_accuracy: 0.8827\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 0s 657us/step - loss: 0.6835 - accuracy: 0.8465 - val_loss: 0.5967 - val_accuracy: 0.8838\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 0s 658us/step - loss: 0.6718 - accuracy: 0.8481 - val_loss: 0.5854 - val_accuracy: 0.8848\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 0s 670us/step - loss: 0.6611 - accuracy: 0.8495 - val_loss: 0.5750 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "modelAdagrad = Sequential([\n",
    "    Dense(units=10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "\n",
    "modelAdagrad.compile(optimizer=Adagrad(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "history = modelAdagrad.fit(x_train, y_train, validation_split = 0.1, batch_size=batch_size, epochs=n_epoch)\n",
    "\n",
    "T = T.append(pd.DataFrame(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 0s 904us/step - loss: 0.6395 - accuracy: 0.8420 - val_loss: 0.3046 - val_accuracy: 0.9203\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 0s 718us/step - loss: 0.3429 - accuracy: 0.9047 - val_loss: 0.2619 - val_accuracy: 0.9287\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 0s 805us/step - loss: 0.3116 - accuracy: 0.9143 - val_loss: 0.2462 - val_accuracy: 0.9322\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 0s 722us/step - loss: 0.2967 - accuracy: 0.9170 - val_loss: 0.2393 - val_accuracy: 0.9323\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 0s 727us/step - loss: 0.2880 - accuracy: 0.9194 - val_loss: 0.2344 - val_accuracy: 0.9330\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 0s 740us/step - loss: 0.2820 - accuracy: 0.9221 - val_loss: 0.2294 - val_accuracy: 0.9372\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 0s 695us/step - loss: 0.2775 - accuracy: 0.9224 - val_loss: 0.2278 - val_accuracy: 0.9372\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 0s 722us/step - loss: 0.2742 - accuracy: 0.9236 - val_loss: 0.2253 - val_accuracy: 0.9380\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 0s 756us/step - loss: 0.2713 - accuracy: 0.9245 - val_loss: 0.2251 - val_accuracy: 0.9382\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 0s 689us/step - loss: 0.2692 - accuracy: 0.9258 - val_loss: 0.2275 - val_accuracy: 0.9373\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 0s 672us/step - loss: 0.2671 - accuracy: 0.9267 - val_loss: 0.2260 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 0s 723us/step - loss: 0.2654 - accuracy: 0.9272 - val_loss: 0.2237 - val_accuracy: 0.9405\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 0s 670us/step - loss: 0.2640 - accuracy: 0.9280 - val_loss: 0.2216 - val_accuracy: 0.9408\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 0s 669us/step - loss: 0.2628 - accuracy: 0.9278 - val_loss: 0.2248 - val_accuracy: 0.9388\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 0s 691us/step - loss: 0.2616 - accuracy: 0.9282 - val_loss: 0.2226 - val_accuracy: 0.9392\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 0s 688us/step - loss: 0.2606 - accuracy: 0.9289 - val_loss: 0.2217 - val_accuracy: 0.9398\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 0s 676us/step - loss: 0.2596 - accuracy: 0.9296 - val_loss: 0.2241 - val_accuracy: 0.9392\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 0s 670us/step - loss: 0.2587 - accuracy: 0.9298 - val_loss: 0.2214 - val_accuracy: 0.9405\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 0s 668us/step - loss: 0.2579 - accuracy: 0.9296 - val_loss: 0.2204 - val_accuracy: 0.9412\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 0s 669us/step - loss: 0.2573 - accuracy: 0.9297 - val_loss: 0.2194 - val_accuracy: 0.9420\n"
     ]
    }
   ],
   "source": [
    "modelRMSprop = Sequential([\n",
    "    Dense(units=10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "\n",
    "modelRMSprop.compile(optimizer=RMSprop(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "history = modelRMSprop.fit(x_train, y_train, validation_split = 0.1, batch_size=batch_size, epochs=n_epoch)\n",
    "\n",
    "T = T.append(pd.DataFrame(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.to_csv(\"/Users/benjamintenmann/Desktop/CompBio/Assignments/DL_1/MNIST/hist_prc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9267\n",
      "Adam: 0.2637287974357605 0.9266999959945679\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.8623\n",
      "Adagrad: 0.6254975199699402 0.8622999787330627\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.9272\n",
      "RMSprop: 0.26703643798828125 0.9272000193595886\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "loss, acc = modelAdam.evaluate(val_dataset)\n",
    "print(\"Adam:\", loss, acc)\n",
    "loss, acc = modelAdagrad.evaluate(val_dataset)\n",
    "print(\"Adagrad:\", loss, acc)\n",
    "loss, acc = modelRMSprop.evaluate(val_dataset)\n",
    "print(\"RMSprop:\", loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
